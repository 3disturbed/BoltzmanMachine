<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>Patch-Based RBM: Train + Test Denoising</title>
  <style>
    body { font-family: sans-serif; }
    .canvas-container {
      display: flex;
      gap: 20px;
      margin-bottom: 20px;
      flex-wrap: wrap;
    }
    canvas {
      border: 1px solid black;
      image-rendering: pixelated; /* makes the blocky patches more visible */
    }
  </style>
</head>
<body>

<h1>Patch-Based RBM Denoising Demo</h1>
<p>
  1) Upload a <strong>training image</strong> (clean) to learn RBMs (24×24 patches).  
  2) Upload a <strong>noisy test image</strong> of the <em>exact same size</em> to denoise it.
</p>

<!-- Buttons for training & testing -->
<div>
  <label>Training Image: <input type="file" id="trainFileInput" accept="image/*"></label>
</div>
<div style="margin-top:1em;">
  <label>Noisy Test Image: <input type="file" id="testFileInput" accept="image/*"></label>
</div>

<!-- Canvases to show results -->
<div class="canvas-container">
  <div>
    <p>Training Image (cropped to multiples of 24×24)</p>
    <canvas id="canvasTrain"></canvas>
  </div>
  <div>
    <p>Noisy Test Image (same size)</p>
    <canvas id="canvasTest"></canvas>
  </div>
  <div>
    <p>Denoised Output</p>
    <canvas id="canvasDenoised"></canvas>
  </div>
</div>

<script>
/*
  Global Configuration & Data
*/
const PATCH_SIZE = 24;       // We'll do 24×24 patches
const CHANNELS = 3;         // R,G,B
const EPOCHS = 20;          // RBM epochs per patch (toy example)
const HIDDEN_SIZE = 64;     // RBM hidden units (per patch)
const LEARNING_RATE = 0.1;  // RBM learning rate

// Training image info
let trainWidth = 0;
let trainHeight = 0;
let trainPatchRows = 0;
let trainPatchCols = 0;
let trainProcessedWidth = 0;
let trainProcessedHeight = 0;

// We'll store the RBM parameters for each patch in an array.
// patchModels[patchIndex] = { W, bVisible, bHidden }
let patchModels = [];

// Canvas contexts
let ctxTrain, ctxTest, ctxDenoised;

// Once the user loads the training image, we set up these canvases.
const canvasT = document.getElementById('canvasTrain');
const canvasTest = document.getElementById('canvasTest');
const canvasD = document.getElementById('canvasDenoised');

ctxTrain = canvasT.getContext('2d');
ctxTest = canvasTest.getContext('2d');
ctxDenoised = canvasD.getContext('2d');

/*
  1) TRAINING IMAGE UPLOAD
*/
document.getElementById('trainFileInput').addEventListener('change', (e) => {
  const file = e.target.files[0];
  if (!file) return;

  const reader = new FileReader();
  reader.onload = (event) => {
    const img = new Image();
    img.onload = () => {
      // Set the training image size
      trainWidth = img.naturalWidth;
      trainHeight = img.naturalHeight;

      // Determine how many 24×24 patches fit
      trainPatchRows = Math.floor(trainWidth / PATCH_SIZE);
      trainPatchCols = Math.floor(trainHeight / PATCH_SIZE);

      trainProcessedWidth = trainPatchRows * PATCH_SIZE;
      trainProcessedHeight = trainPatchCols * PATCH_SIZE;

      console.log(`Training image: ${trainWidth}×${trainHeight}`);
      console.log(`Will train on region: ${trainProcessedWidth}×${trainProcessedHeight}`);

      // Resize the canvas to match the processed area
      canvasT.width = trainProcessedWidth;
      canvasT.height = trainProcessedHeight;

      // Draw the training image on a temp canvas
      const tempCanvas = document.createElement('canvas');
      tempCanvas.width = trainWidth;
      tempCanvas.height = trainHeight;
      const tempCtx = tempCanvas.getContext('2d');
      tempCtx.drawImage(img, 0, 0);

      // Extract the pixel data
      const fullData = tempCtx.getImageData(0, 0, trainWidth, trainHeight).data;

      // Crop to the region we can handle
      // (We'll just ignore leftover pixels if trainWidth or trainHeight isn't multiple of 24)
      const pixelData = extractRegion(fullData, trainWidth, trainHeight, 0, 0, trainProcessedWidth, trainProcessedHeight);

      // Draw that portion onto the "training canvas"
      const trainImageData = ctxTrain.createImageData(trainProcessedWidth, trainProcessedHeight);
      trainImageData.data.set(pixelData);
      ctxTrain.putImageData(trainImageData, 0, 0);

      // Split into patches, train RBMs
      trainRBMsFromImageData(pixelData, trainProcessedWidth, trainProcessedHeight);
    };
    img.src = event.target.result;
  };
  reader.readAsDataURL(file);
});

/*
  2) TEST (NOISY) IMAGE UPLOAD
*/
document.getElementById('testFileInput').addEventListener('change', (e) => {
  const file = e.target.files[0];
  if (!file) return;

  // If no patchModels exist yet, we haven't trained anything.
  if (patchModels.length === 0) {
    alert("You haven't trained yet. Please upload a training image first!");
    return;
  }

  const reader = new FileReader();
  reader.onload = (event) => {
    const img = new Image();
    img.onload = () => {
      // The test image must be the same size as the training region
      const tWidth = img.naturalWidth;
      const tHeight = img.naturalHeight;
      if (tWidth !== trainProcessedWidth || tHeight !== trainProcessedHeight) {
        alert(`Test image is ${tWidth}×${tHeight}, but training region is ${trainProcessedWidth}×${trainProcessedHeight}. They must match!`);
        return;
      }

      console.log(`Test (noisy) image loaded: ${tWidth}×${tHeight}`);

      // Resize test & denoised canvases
      canvasTest.width = tWidth;
      canvasTest.height = tHeight;
      canvasD.width = tWidth;
      canvasD.height = tHeight;

      const tempCanvas = document.createElement('canvas');
      tempCanvas.width = tWidth;
      tempCanvas.height = tHeight;
      const tempCtx = tempCanvas.getContext('2d');
      tempCtx.drawImage(img, 0, 0);

      // Extract pixel data for the entire image
      const fullData = tempCtx.getImageData(0, 0, tWidth, tHeight).data;
      // We'll just use it directly; it should match the training dimension
      const testImageData = ctxTest.createImageData(tWidth, tHeight);
      testImageData.data.set(fullData);
      ctxTest.putImageData(testImageData, 0, 0);

      // Now reconstruct (denoise) patch by patch
      denoiseTestImage(fullData, tWidth, tHeight);
    };
    img.src = event.target.result;
  };
  reader.readAsDataURL(file);
});

/*
  extractRegion:
  - Given RGBA data, extract the subregion [x, x+width) × [y, y+height)
  - Return the RGBA array for that region
*/
function extractRegion(rgbaData, fullW, fullH, startX, startY, cropW, cropH) {
  const output = new Uint8ClampedArray(cropW * cropH * 4);
  for (let row = 0; row < cropH; row++) {
    for (let col = 0; col < cropW; col++) {
      const sx = startX + col;
      const sy = startY + row;
      const srcIndex = (sy * fullW + sx) * 4;
      const dstIndex = (row * cropW + col) * 4;
      output[dstIndex + 0] = rgbaData[srcIndex + 0];
      output[dstIndex + 1] = rgbaData[srcIndex + 1];
      output[dstIndex + 2] = rgbaData[srcIndex + 2];
      output[dstIndex + 3] = rgbaData[srcIndex + 3];
    }
  }
  return output;
}

/*
  trainRBMsFromImageData:
  - Takes the RGBA pixelData for the region
  - Splits into 24×24 patches (for each patch, we binarize + train an RBM)
  - Stores the resulting models in `patchModels`
*/
function trainRBMsFromImageData(pixelData, width, height) {
  patchModels = []; // clear old data

  console.log(`Splitting into patches of size ${PATCH_SIZE}×${PATCH_SIZE}...`);
  // compute how many patches
  const rows = Math.floor(height / PATCH_SIZE);
  const cols = Math.floor(width / PATCH_SIZE);
  const totalPatches = rows * cols;
  console.log(`Total patches: ${totalPatches}`);

  // For each patch:
  let patchIndex = 0;
  for (let py = 0; py < rows; py++) {
    for (let px = 0; px < cols; px++) {
      // Extract the patch's RGBA data
      const patchRGBA = new Uint8Array(PATCH_SIZE * PATCH_SIZE * 4);
      for (let iy = 0; iy < PATCH_SIZE; iy++) {
        for (let ix = 0; ix < PATCH_SIZE; ix++) {
          const gx = px * PATCH_SIZE + ix;
          const gy = py * PATCH_SIZE + iy;
          const srcIndex = (gy * width + gx) * 4;
          const dstIndex = (iy * PATCH_SIZE + ix) * 4;
          patchRGBA[dstIndex + 0] = pixelData[srcIndex + 0];
          patchRGBA[dstIndex + 1] = pixelData[srcIndex + 1];
          patchRGBA[dstIndex + 2] = pixelData[srcIndex + 2];
          patchRGBA[dstIndex + 3] = pixelData[srcIndex + 3];
        }
      }

      // Convert RGBA to binary [0 or 1 for R, G, B]
      const binaryPatch = rgbaToBinary(patchRGBA, PATCH_SIZE, PATCH_SIZE);

      // Train an RBM on this single patch
      const model = trainRBM(binaryPatch); 
      patchModels.push(model);

      patchIndex++;
      if (patchIndex % 100 === 0) {
        console.log(`Trained patch ${patchIndex} / ${totalPatches}`);
      }
    }
  }
  console.log("Training complete for all patches!");
}

/*
  denoiseTestImage:
  - Split test image into patches
  - For each patch, binarize, run the stored RBM for that patch to reconstruct
  - Combine all reconstructed patches into the final canvas
*/
function denoiseTestImage(pixelData, width, height) {
  const rows = Math.floor(height / PATCH_SIZE);
  const cols = Math.floor(width / PATCH_SIZE);

  let patchIndex = 0;
  const outputCanvasData = ctxDenoised.createImageData(width, height);

  for (let py = 0; py < rows; py++) {
    for (let px = 0; px < cols; px++) {
      // Extract patch RGBA
      const patchRGBA = new Uint8Array(PATCH_SIZE * PATCH_SIZE * 4);
      for (let iy = 0; iy < PATCH_SIZE; iy++) {
        for (let ix = 0; ix < PATCH_SIZE; ix++) {
          const gx = px * PATCH_SIZE + ix;
          const gy = py * PATCH_SIZE + iy;
          const srcIndex = (gy * width + gx) * 4;
          const dstIndex = (iy * PATCH_SIZE + ix) * 4;
          patchRGBA[dstIndex + 0] = pixelData[srcIndex + 0];
          patchRGBA[dstIndex + 1] = pixelData[srcIndex + 1];
          patchRGBA[dstIndex + 2] = pixelData[srcIndex + 2];
          patchRGBA[dstIndex + 3] = pixelData[srcIndex + 3];
        }
      }

      // Convert to binary
      const noisyBinaryPatch = rgbaToBinary(patchRGBA, PATCH_SIZE, PATCH_SIZE);

      // Reconstruct using the patch's learned model
      const model = patchModels[patchIndex];
      const reconstructed = reconstructPatch(noisyBinaryPatch, model);

      // Convert back to RGBA
      const reconstructedRGBA = binaryToRGBA(reconstructed, PATCH_SIZE, PATCH_SIZE);

      // Write into outputCanvasData
      for (let iy = 0; iy < PATCH_SIZE; iy++) {
        for (let ix = 0; ix < PATCH_SIZE; ix++) {
          const gx = px * PATCH_SIZE + ix;
          const gy = py * PATCH_SIZE + iy;
          const dstIndex = (gy * width + gx) * 4;
          const srcIndex = (iy * PATCH_SIZE + ix) * 4;
          outputCanvasData.data[dstIndex + 0] = reconstructedRGBA[srcIndex + 0];
          outputCanvasData.data[dstIndex + 1] = reconstructedRGBA[srcIndex + 1];
          outputCanvasData.data[dstIndex + 2] = reconstructedRGBA[srcIndex + 2];
          outputCanvasData.data[dstIndex + 3] = reconstructedRGBA[srcIndex + 3];
        }
      }

      patchIndex++;
    }
  }

  // Put the reconstructed data onto the canvas
  ctxDenoised.putImageData(outputCanvasData, 0, 0);
  console.log("Denoising complete!");
}

/*
  RGBA -> [0 or 1 for R, G, B]
*/
function rgbaToBinary(rgbaArray, w, h) {
  const output = new Uint8Array(w * h * CHANNELS);
  // threshold each channel at 128
  for (let i = 0; i < w*h; i++) {
    const r = rgbaArray[i*4 + 0];
    const g = rgbaArray[i*4 + 1];
    const b = rgbaArray[i*4 + 2];
    output[i*3 + 0] = (r > 128) ? 1 : 0;
    output[i*3 + 1] = (g > 128) ? 1 : 0;
    output[i*3 + 2] = (b > 128) ? 1 : 0;
  }
  return output;
}

/*
  Binary [R,G,B] -> RGBA
*/
function binaryToRGBA(binArray, w, h) {
  const output = new Uint8ClampedArray(w * h * 4);
  for (let i = 0; i < w*h; i++) {
    const r = binArray[i*3 + 0] * 255;
    const g = binArray[i*3 + 1] * 255;
    const b = binArray[i*3 + 2] * 255;
    output[i*4 + 0] = r;
    output[i*4 + 1] = g;
    output[i*4 + 2] = b;
    output[i*4 + 3] = 255;
  }
  return output;
}

/*
  trainRBM:
  - Trains a small RBM on a single patch (which is one data point in this toy demo).
  - Returns {W, bVisible, bHidden}.
*/
function trainRBM(patchBinary) {
  const visibleSize = patchBinary.length; // e.g. 24*24*3 = 1728
  // Initialize parameters
  let W = [];
  for (let i = 0; i < visibleSize; i++) {
    W[i] = new Float32Array(HIDDEN_SIZE);
    for (let j = 0; j < HIDDEN_SIZE; j++) {
      W[i][j] = (Math.random() * 0.1 - 0.05);
    }
  }
  let bVisible = new Float32Array(visibleSize);
  let bHidden = new Float32Array(HIDDEN_SIZE);

  // training for EPOCHS
  for (let e = 0; e < EPOCHS; e++) {
    contrastiveDivergence(patchBinary, W, bVisible, bHidden);
  }

  return { W, bVisible, bHidden };
}

/*
  contrastiveDivergence:
  - One step of CD-1 on a single sample "vData".
*/
function contrastiveDivergence(vData, W, bVisible, bHidden) {
  const visibleSize = vData.length;
  // Positive phase
  const hProbData = computeHiddenProb(vData, W, bHidden);
  const hSampleData = new Uint8Array(HIDDEN_SIZE);
  for (let j = 0; j < HIDDEN_SIZE; j++) {
    hSampleData[j] = sampleBinary(hProbData[j]);
  }

  // Negative phase
  const vProbRec = computeVisibleProb(hSampleData, W, bVisible);
  const vSampleRec = new Uint8Array(visibleSize);
  for (let i = 0; i < visibleSize; i++) {
    vSampleRec[i] = sampleBinary(vProbRec[i]);
  }
  const hProbRec = computeHiddenProb(vSampleRec, W, bHidden);

  // Update weights
  for (let i = 0; i < visibleSize; i++) {
    for (let j = 0; j < HIDDEN_SIZE; j++) {
      const pos = vData[i] * hProbData[j];
      const neg = vSampleRec[i] * hProbRec[j];
      W[i][j] += LEARNING_RATE * (pos - neg);
    }
  }
  // Update biases
  for (let i = 0; i < visibleSize; i++) {
    bVisible[i] += LEARNING_RATE * (vData[i] - vSampleRec[i]);
  }
  for (let j = 0; j < HIDDEN_SIZE; j++) {
    bHidden[j] += LEARNING_RATE * (hProbData[j] - hProbRec[j]);
  }
}

/*
  reconstructPatch:
  - Given a "noisy" patch and an already-trained model {W, bVisible, bHidden},
    produce the reconstructed (denoised) patch.
*/
function reconstructPatch(noisyPatch, model) {
  const { W, bVisible, bHidden } = model;
  const visibleSize = noisyPatch.length;

  // compute hidden from the noisy patch
  const hProb = computeHiddenProb(noisyPatch, W, bHidden);
  const hSample = new Uint8Array(HIDDEN_SIZE);
  for (let j = 0; j < HIDDEN_SIZE; j++) {
    hSample[j] = sampleBinary(hProb[j]);
  }

  // reconstruct
  const vProb = computeVisibleProb(hSample, W, bVisible);
  const vRec = new Uint8Array(visibleSize);
  for (let i = 0; i < visibleSize; i++) {
    vRec[i] = (vProb[i] > 0.5) ? 1 : 0;
  }
  return vRec;
}

/*
  RBM Utility Functions
*/
function computeHiddenProb(v, W, bHidden) {
  const hiddenProb = new Float32Array(HIDDEN_SIZE);
  for (let j = 0; j < HIDDEN_SIZE; j++) {
    let sum = bHidden[j];
    for (let i = 0; i < v.length; i++) {
      sum += v[i] * W[i][j];
    }
    hiddenProb[j] = sigmoid(sum);
  }
  return hiddenProb;
}

function computeVisibleProb(h, W, bVisible) {
  const visibleProb = new Float32Array(bVisible.length);
  for (let i = 0; i < visibleProb.length; i++) {
    let sum = bVisible[i];
    for (let j = 0; j < HIDDEN_SIZE; j++) {
      sum += h[j] * W[i][j];
    }
    visibleProb[i] = sigmoid(sum);
  }
  return visibleProb;
}

function sigmoid(x) {
  return 1 / (1 + Math.exp(-x));
}

function sampleBinary(prob) {
  return (Math.random() < prob) ? 1 : 0;
}

</script>

</body>
</html>
